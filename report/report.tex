\documentclass[11pt, twocolumn, a4paper]{article}
\usepackage[a4paper, left = 2cm, right = 2cm, top = 2cm, bottom = 2cm]{geometry}
\usepackage[style = numeric, sorting = none, urldate = long]{biblatex}
\usepackage{listings}
% \usepackage{amsmath}
% \usepackage{graphicx}
% \usepackage{subfig}
\usepackage{subfig}

% \graphicspath{{./images/}}
\addbibresource{refs.bib}

\author{
    George Herbert\\
    \texttt{cj19328@bristol.ac.uk}
}

\title{Optimisations and Parallelism of d2q9-bgk.c}
\begin{document}

\maketitle

\begin{abstract}
    \texttt{d2q9-bgk.c} implements the Lattice Boltzmann methods (LBM) to simulate a fluid density on a lattice.
    This report outlines the techniques I utilised to optimise and parallelise \texttt{d2q9-bgk.c}, as well as a detailed analysis of those techniques.
    To do so, this report is split into several sections corresponding to different iterations of my code.
\end{abstract}

\section{Original code}

I compiled the original \texttt{d2q9-bgk.c} using the GNU Compiler Collection (GCC) with the following command:
\begin{lstlisting}[language=bash, breaklines=true]
gcc -std=c99 -Wall d2q9-bgk.c -lm -o d2q9-bgk.
\end{lstlisting}

\begin{table}[htbp]
    \begin{center}
    \caption{Total time of the original code for test cases of different sizes}\label{tab:original}
    \begin{tabular}{l | l} 
        \hline\hline
        Test Case Size&Time (s)\\
        \hline
        $128 \times 128$&0\\
        $128 \times 256$&0\\
        $256 \times 256$&0\\
        $1024 \times 1024$&0\\
        \hline
      \end{tabular}
    \end{center}
\end{table} 


Figure \ref{tab:original} contains the total time to initialise, compute and collate each of the test cases when running the ELF file.
It was important to measure the original code, so that I could quantify the performnace improvements of my latter implementations.
I measured each of the total times by taking an average of 10 runs on BlueCrystal Phase 4's (BC4's) compute nodes.
Each of BC4's compute nodes is a Lenovo nx360 M5, which contains two 14-core 2.4 GHz Intel E5-2680 v4 (Broadwell) CPUs and 128 GiB of RAM \cite{bcp4}.
I took an average of multiple runs because of the variation between runs, which exists due to the inconsistent performance of compute nodes.
% Not all compute nodes offer the same performance all of the time, due to differing placement in the data centre, amongst other reasons.

\section{Serial optimisations}

\subsection{Compiler}

\subsection{Code changes}

\subsection{Results}

\begin{table}[htbp]
    \begin{center}
    \caption{Total time of the serial optimised code for test cases of different sizes}\label{tab:serial_optimised}
    \begin{tabular}{l | l} 
        \hline\hline
        Test Case Size&Time (s)\\
        \hline
        $128 \times 128$&0\\
        $128 \times 256$&0\\
        $256 \times 256$&0\\
        $1024 \times 1024$&0\\
        \hline
      \end{tabular}
    \end{center}
\end{table} 

\section{Vectorization}

\subsection{Code changes}

\subsection{Results}

\begin{table}[htbp]
    \begin{center}
    \caption{Total time of the vectorized code for test cases of different sizes}\label{tab:vectorized}
    \begin{tabular}{l | l} 
        \hline\hline
        Test Case Size&Time (s)\\
        \hline
        $128 \times 128$&0\\
        $128 \times 256$&0\\
        $256 \times 256$&0\\
        $1024 \times 1024$&0\\
        \hline
      \end{tabular}
    \end{center}
\end{table} 

\section{Parallelism}

\subsection{OpenMP}

\subsection{Results}

\begin{table}[htbp]
    \begin{center}
    \caption{Total time of the parallelised code for test cases of different sizes}\label{tab:parallelised}
    \begin{tabular}{l | l} 
        \hline\hline
        Test Case Size&Time (s)\\
        \hline
        $128 \times 128$&0\\
        $128 \times 256$&0\\
        $256 \times 256$&0\\
        $1024 \times 1024$&0\\
        \hline
      \end{tabular}
    \end{center}
\end{table} 

\clearpage

\onecolumn{
  \printbibliography
}

\end{document}