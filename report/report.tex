\documentclass[11pt, twocolumn, a4paper]{article}
\usepackage[a4paper, left = 2cm, right = 2cm, top = 2cm, bottom = 2cm]{geometry}
\usepackage[style = numeric, sorting = none, urldate = long]{biblatex}
\usepackage{listings}
\usepackage{subfig}
% \usepackage{amsmath}
% \usepackage{graphicx}


% \graphicspath{{./images/}}
\addbibresource{refs.bib}

\author{
    George Herbert\\
    \texttt{cj19328@bristol.ac.uk}
}

\title{Optimisations and Parallelism of d2q9-bgk.c}
\begin{document}

\maketitle

\begin{abstract}
    \texttt{d2q9-bgk.c} implements the Lattice Boltzmann methods (LBM) to simulate a fluid density on a lattice.
    This report outlines the techniques I utilised to optimise and parallelise \texttt{d2q9-bgk.c}, as well as a detailed analysis of those techniques.
    To do so, this report is split into several sections corresponding to different iterations of my code.
\end{abstract}

\section{Original code}

I compiled the original \texttt{d2q9-bgk.c} using the GNU Compiler Collection (GCC) with the following command:
\begin{lstlisting}[language=bash, breaklines=true]
gcc -std=c99 -Wall d2q9-bgk.c -lm -o d2q9-bgk.
\end{lstlisting}

\begin{table}[htbp]
    \begin{center}
    \caption{Total time of the original code for test cases of different sizes}\label{tab:original}
    \begin{tabular}{l | l} 
        \hline\hline
        Test Case Size&Time (s)\\
        \hline
        $128 \times 128$&\texttt{0}\\
        $128 \times 256$&\texttt{0}\\
        $256 \times 256$&\texttt{0}\\
        $1024 \times 1024$&\texttt{0}\\
        \hline
      \end{tabular}
    \end{center}
\end{table} 


Figure \ref{tab:original} contains the total time to initialise, compute and collate each of the test cases when running the ELF file produced.
It was important to measure the original code, so that I could quantify the performance improvements of my latter implementations.
I measured each of the total times by taking an average of 10 runs on BlueCrystal Phase 4's (BC4's) compute nodes.
Each of BC4's compute nodes is a Lenovo nx360 M5, which contains two 14-core 2.4 GHz Intel E5-2680 v4 (Broadwell) CPUs and 128 GiB of RAM \cite{bcp4}.
I took an average of multiple runs because of the variation between runs, which exists due to the inconsistent performance of compute nodes.
% Not all compute nodes offer the same performance all of the time, due to differing placement in the data centre, amongst other reasons.

\section{Serial optimised}

\subsection{Optimisations}

I compiled my serial optimised implementation using the IntelÂ® C Compiler as opposed to GCC, since it provides better optimised code for Intel processors.
Furthermore, I compiled my code with the \texttt{Ofast} flag, which set aggressive options to improve the speed of my program, including \texttt{O3} optimisations and aggressive floating point optimisations \cite{icc}.

LBM is a memory bound problem.
As a result of this, there was a significant opportunity to optimise \texttt{d2q9-bgk.c} by decreasing the number of memory accesses.
One method I utilised to accomplish this was loop fusion.
In the original code, the entire grid was iterated over in four sequential procedures within each timestep: \texttt{propagate}, \texttt{rebound}, \texttt{collision} and \texttt{av\_velocity}.
By fusing the four loops in these procedures into one, I was able to drastically decrease the number of memory accesses, thereby improving the performance of my program.

Implementing loop fusion offered another significant opportunity to eliminate redundant memory accesses.
The original code had a significant quantity of value copying between the \texttt{cells} and \texttt{tmp\_cells} arrays.
I was able to eliminate this by writing all new values of cells to a \texttt{cells\_new} array, and simply swapping the pointers of \texttt{cells\_new} and \texttt{cells} at the end of each timestep.
Furthermore, I eliminated the \texttt{tmp\_cells} array entirely.

Despite the compiler being able to optimise the arithmetic within each timestep without making any changes to the code, there were still some manual improvements that I made to improve the performance of the program.
Division is a very slow arithmetic operation relative to multiplication.
Therefore, to eliminate a large number of unnecessary division operations I precalculated several values including:
\[
    \frac{1}{c^2} = 3\qquad
    \frac{1}{2c^2} = 1.5\qquad
    \frac{1}{2c^4} = 4.5
\]
where $c$ is the speed of sound.
Additionally, I noticed that the number of cells in the grid that were not obstacles \texttt{tot\_u} was recalculated and then divided by each timestep.
I eliminated this inefficiency by counting number of cells that were not obstacles only once (during the initialisation phase).
I then saved the reciprocol of this value as a parameter \texttt{num\_non\_obstacles\_r}, which I used once per timestep in a multiplicative operation to compute the average velocity.


\subsection{Results}

\begin{table}[htbp]
    \begin{center}
    \caption{Total time of the serial optimised code for test cases of different sizes}\label{tab:serial_optimised}
    \begin{tabular}{l | l} 
        \hline\hline
        Test Case Size&Time (s)\\
        \hline
        $128 \times 128$&\texttt{ 19.10}\\
        $128 \times 256$&\texttt{ 38.49}\\
        $256 \times 256$&\texttt{153.39}\\
        $1024 \times 1024$&\texttt{621.52}\\
        \hline
      \end{tabular}
    \end{center}
\end{table} 

\section{Vectorized}

\subsection{Optimisations}

\subsection{Results}

\begin{table}[htbp]
    \begin{center}
    \caption{Total time of the vectorized code for test cases of different sizes}\label{tab:vectorized}
    \begin{tabular}{l | l} 
        \hline\hline
        Test Case Size&Time (s)\\
        \hline
        $128 \times 128$&\texttt{  \,\,\,5.79}\\
        $128 \times 256$&\texttt{ 11.66}\\
        $256 \times 256$&\texttt{ 40.81}\\
        $1024 \times 1024$&\texttt{213.53}\\
        \hline
      \end{tabular}
    \end{center}
\end{table} 

\section{Parallelised}

\subsection{OpenMP}

\subsection{Results}

\begin{table}[htbp]
    \begin{center}
    \caption{Total time of the parallelised code for test cases of different sizes}\label{tab:parallelised}
    \begin{tabular}{l | l} 
        \hline\hline
        Test Case Size&Time (s)\\
        \hline
        $128 \times 128$&\texttt{ 0.79}\\
        $128 \times 256$&\texttt{ 0.91}\\
        $256 \times 256$&\texttt{ 2.85}\\
        $1024 \times 1024$&\texttt{13.43}\\
        \hline
      \end{tabular}
    \end{center}
\end{table} 

\clearpage

\onecolumn{
  \printbibliography
}

\end{document}